{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# En caso de problemas, utilizar las dependencias de librerías de este requierement: https://github.com/googlecolab/backend-info/blob/d6d345cb94fc5fd49951c9af0f6ead5e962bfab2/pip-freeze.txt\n",
        "!pip install numpy==1.23.5\n",
        "!pip install transformers[torch]==4.35.2\n",
        "!pip install accelerate -U\n",
        "!pip install evaluate"
      ],
      "metadata": {
        "id": "wG7EP2fFgoTn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ff2ba7c-50b2-4136-b809-1152824bf880"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Collecting transformers[torch]==4.35.2\n",
            "  Using cached transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]==4.35.2) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]==4.35.2) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]==4.35.2) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]==4.35.2) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]==4.35.2) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]==4.35.2) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]==4.35.2) (2.31.0)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers[torch]==4.35.2)\n",
            "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]==4.35.2) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]==4.35.2) (4.66.4)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]==4.35.2) (2.2.1+cu121)\n",
            "Collecting accelerate>=0.20.3 (from transformers[torch]==4.35.2)\n",
            "  Using cached accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]==4.35.2) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]==4.35.2) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]==4.35.2) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]==4.35.2) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]==4.35.2) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]==4.35.2) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]==4.35.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]==4.35.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]==4.35.2) (12.1.105)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch!=1.12.0,>=1.10->transformers[torch]==4.35.2)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]==4.35.2) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]==4.35.2) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]==4.35.2) (10.3.2.106)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch!=1.12.0,>=1.10->transformers[torch]==4.35.2)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]==4.35.2) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]==4.35.2) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]==4.35.2) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]==4.35.2) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch!=1.12.0,>=1.10->transformers[torch]==4.35.2) (12.4.127)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]==4.35.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]==4.35.2) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]==4.35.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]==4.35.2) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]==4.35.2) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]==4.35.2) (1.3.0)\n",
            "Installing collected packages: nvidia-cudnn-cu12, nvidia-cusolver-cu12, tokenizers, transformers, accelerate\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.40.2\n",
            "    Uninstalling transformers-4.40.2:\n",
            "      Successfully uninstalled transformers-4.40.2\n",
            "Successfully installed accelerate-0.30.1 nvidia-cudnn-cu12-8.9.2.26 nvidia-cusolver-cu12-11.4.5.107 tokenizers-0.15.2 transformers-4.35.2\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets>=2.0.0 (from evaluate)\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.23.5)\n",
            "Collecting dill (from evaluate)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.4)\n",
            "Collecting xxhash (from evaluate)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from evaluate)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.14.0)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.5)\n",
            "Collecting huggingface-hub>=0.7.0 (from evaluate)\n",
            "  Downloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, huggingface-hub, datasets, evaluate\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "Successfully installed datasets-2.19.1 dill-0.3.8 evaluate-0.4.2 huggingface-hub-0.23.0 multiprocess-0.70.16 xxhash-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pOub-BB9KWh5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "def load_prepare_data(path):\n",
        "  \"\"\"\n",
        "  Función para cargar y procesar datos para el ejercicio.\n",
        "  \"\"\"\n",
        "  df = pd.read_csv(path,sep=\",\")\n",
        "  map_classes = {\n",
        "    \"religion\":1,\n",
        "    \"age\":1,\n",
        "    \"ethnicity\":1,\n",
        "    \"gender\":1,\n",
        "    \"other_cyberbullying\":1,\n",
        "    \"not_cyberbullying\":0,\n",
        "  }\n",
        "  df[\"cyberbullying\"] = df.cyberbullying_type.map(map_classes)\n",
        "  return df[[\"tweet_text\",\"cyberbullying\"]].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio\n"
      ],
      "metadata": {
        "id": "OeczIz9uKyBV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este ejercicio vamos a trabajar con un conjunto de datos procedente de medios sociales online.\n",
        "\n",
        "Uno de los mayores problemas en el internet de hoy en día es la presencia de actitudes negativas hacia algunos colectivos en relación a su etnia, género, religión o ideología política. En este ejercicio trabajaremos con un conjunto de datos reales, etiquetados manualmente, procedentes de la plataforma [Kaggle](https://www.kaggle.com/datasets/andrewmvd/cyberbullying-classification/data). Originalmente, a cada documento del dataset se le asignó una de las siguientes categorías:\n",
        "- *religion*\n",
        "- *age*\n",
        "- *ethnicity*\n",
        "- *gender*\n",
        "- *other_cyberbullying*\n",
        "- *not_cyberbullying*\n",
        "\n",
        "\n",
        "El objetivo inicial del dataset era su uso para entrenar un modelo capaz de detectar el tipo de contenido de odio presente en internet según el colectivo al que se atacaba. En este caso, para simplificar el ejercicio, se ha generado una función `load_prepare_data()` que cambia las categorías del dataset obteníendose al final 2 categorías con valor 1 o 0, indicando si el tweet tiene contenido de odio"
      ],
      "metadata": {
        "id": "I9EFBbmM5w90"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**En este ejercicio debeis entrenar un modelo de clasificación utilizando la librería Transformers.** Dado que el análisis exploratorio ha sido realizado en el ejercicio anterior, en este caso podréis centraros en entrenar el modelo utilizando la librería Transformers, seleccionando un modelo pre-entrenado adecuado, entrenando el modelo y llevando a cabo la evaluación.\n",
        "\n",
        "\n",
        "**Nota 1**: Este ejercicio requiere el uso de las GPUs de Google Colab. Este Colab debería estar preconfigurado para ejecutarse en GPU, pero si tuviera problemas en la ejecución que me contacte a través del Moodle para buscar soluciones alternativas."
      ],
      "metadata": {
        "id": "8c1vV6Aogbxu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Imports\n"
      ],
      "metadata": {
        "id": "u5dR3XnT7Wl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "   AutoConfig,\n",
        "   AutoTokenizer,\n",
        "   AutoModelForSequenceClassification,\n",
        "   AdamW\n",
        ")\n",
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sys\n",
        "from tqdm.autonotebook import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "import string\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "fVOCm6Kw7WCW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0bfddbb-336d-4e18-fa2f-63059ac5be88"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Obtención del corpus\n",
        "Para la obtención de los datos teneis disponible la función `load_prepare_data()`. Esta función prepara los datos del ejercicio en formato Pandas dataframe para que podais realizarlo."
      ],
      "metadata": {
        "id": "WbiU7iHSKd-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_data = \"https://raw.githubusercontent.com/luisgasco/ntic_master_datos/main/datasets/cyberbullying_tweets.csv\"\n",
        "# Path de datos alternativos en caso de que el anterior no funcione (al estar alojado en github puede haber limitaciones\n",
        "# en la descarga.\n",
        "# path_data = \"https://zenodo.org/records/10938455/files/cyberbullying_tweets.csv?download=1\"\n",
        "dataset = load_prepare_data(path_data)"
      ],
      "metadata": {
        "id": "4kMXGAUdgvKo"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head(4)"
      ],
      "metadata": {
        "id": "6dXS2-2JgvKo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "57fa6c9c-12c9-493c-fa8e-541bc23bc8cb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          tweet_text  cyberbullying\n",
              "0  In other words #katandandre, your food was cra...              0\n",
              "1  Why is #aussietv so white? #MKR #theblock #ImA...              0\n",
              "2  @XochitlSuckkks a classy whore? Or more red ve...              0\n",
              "3  @Jason_Gio meh. :P  thanks for the heads up, b...              0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8d120bc-6142-4305-8030-2757bf066754\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>cyberbullying</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In other words #katandandre, your food was cra...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8d120bc-6142-4305-8030-2757bf066754')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d8d120bc-6142-4305-8030-2757bf066754 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d8d120bc-6142-4305-8030-2757bf066754');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-aee2febb-5e92-4556-9341-a67d1061bf28\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aee2febb-5e92-4556-9341-a67d1061bf28')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-aee2febb-5e92-4556-9341-a67d1061bf28 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset",
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 47692,\n  \"fields\": [\n    {\n      \"column\": \"tweet_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 46017,\n        \"samples\": [\n          \"@AndyEaston85 Love how we are teaching the Bullshitters a lesson in football. Miss Bully and his message board posts.\",\n          \"GYUK | Anti-feminist YouTuber doubles down on vile Jess Phillips rape joke while leaping to the defence ...: In a video uploaded Thursday (April 23), former UKIP candidate Benjamin jumped to the defence of retired gay porn actor turned men's rights\\u2026 http://dlvr.it/RVRS8h\",\n          \"@Truth_Haqq Islam declared war on all mankind 1400 years ago. Now we return the favor. http://t.co/av4B4yCQzY\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cyberbullying\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Análisis exploratorio"
      ],
      "metadata": {
        "id": "jJoVvfp77ZeF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podéis saltarlo en este ejercicio."
      ],
      "metadata": {
        "id": "NUmXuDMmhtoS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Preprocesado y Normalización"
      ],
      "metadata": {
        "id": "9wseifFy7b4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = dataset.tweet_text.values  # an array of strings\n",
        "labels = dataset.cyberbullying.values  # an array of integers"
      ],
      "metadata": {
        "id": "aac98seT7cBD"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como trabajamos con la librería Transformers, tenemos que ajustar nuestros datos al formato de entrada esperado por el modelo."
      ],
      "metadata": {
        "id": "VFrkJup-Am4_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dividimos el conjunto de datos en Train-Validation(90%) y Test(10%)"
      ],
      "metadata": {
        "id": "JkUACGL2Asyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=.25, random_state=0,\n",
        "                                                    stratify = labels)\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=.2, random_state=0,stratify = train_labels)"
      ],
      "metadata": {
        "id": "RM7zqczRA1Ta"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al trabajar con la librería Transformers, es importante ajustar nuestros datos al formato de entrada esperado por el modelo. Cada modelo preentrenado utiliza un tokenizador específico diseñado para dividir los textos de manera óptima para su entrada. En este caso, utilizaremos el modelo cardiffnlp/twitter-roberta-base-2019-90m"
      ],
      "metadata": {
        "id": "RXRyPbpZA0B5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"cardiffnlp/twitter-roberta-base-2019-90m\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaNDk227A6CA",
        "outputId": "34c3aeee-2f7b-452a-e5f4-40f946c09e05"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comprobamos con el tokenizador subdivide un texto de ejemplo:"
      ],
      "metadata": {
        "id": "Z2M3zETFA61M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Cats and zebras love to nap in sunny spots\"\n",
        "texto_tokens = tokenizer(texto).tokens()\n",
        "texto_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODLdXBM1A5Ax",
        "outputId": "fb959c7d-64d2-4d44-bfca-da047d0edd88"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>',\n",
              " 'C',\n",
              " 'ats',\n",
              " 'Ġand',\n",
              " 'Ġze',\n",
              " 'br',\n",
              " 'as',\n",
              " 'Ġlove',\n",
              " 'Ġto',\n",
              " 'Ġnap',\n",
              " 'Ġin',\n",
              " 'Ġsunny',\n",
              " 'Ġspots',\n",
              " '</s>']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para poder trabajar con Hugging Face es necesario cargar los datos, siguiendo la estructura basada en Apache Arrow.\n",
        "\n",
        "En este caso, utilzaremos la función CustomDataset(), que tomará la entrada de los textos y etiquetas de cada subset y se prepara el formato requerido para el entrenamiento, realizando la tokenización internamente."
      ],
      "metadata": {
        "id": "y0Ge9IPCA_TX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "dgUbJvgV4Sc7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length):\n",
        "        \"\"\"\n",
        "        Constructor de la clase CustomDataset.\n",
        "        Parámetros:\n",
        "        - texts: Lista de textos.\n",
        "        - labels: Lista de etiquetas correspondientes a los textos.\n",
        "        - tokenizer: Objeto del tokenizador a utilizar.\n",
        "        - max_length: Longitud máxima de la secuencia después de la tokenización.\n",
        "        \"\"\"\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Devuelve la longitud del conjunto de datos.\n",
        "        \"\"\"\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Obtiene un elemento del conjunto de datos.\n",
        "\n",
        "        Parámetros:\n",
        "        - idx: Índice del elemento a obtener.\n",
        "\n",
        "        Devuelve:\n",
        "        Un diccionario con 'input_ids', 'attention_mask' y 'labels'.\n",
        "        \"\"\"\n",
        "        # Obtener el texto y la etiqueta del índice proporcionado\n",
        "        text = str(self.texts[idx])\n",
        "        label = int(self.labels[idx])\n",
        "\n",
        "        # Tokenizar el texto\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_length,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Devolver el diccionario con los datos\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvRgrPYH4YmJ"
      },
      "source": [
        "Ahora, transformaremos nuestros datos al formato Datasets. Cada elemento del nuevo formato tendrá:\n",
        "1. Inputs_ids: Identificadores numéricos de los tokens en el vocabulario del modelo.\n",
        "2. attention_mask: Vector que indica a la red neuronal qué partes de la secuencia de entrada debe prestar atención y cuáles ignorar.\n",
        "3. labels: La etiqueta asociada al texto"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 128  # Puedes ajustar esto según tus necesidades\n",
        "\n",
        "train_dataset = CustomDataset(train_texts, train_labels, tokenizer, max_length)\n",
        "val_dataset = CustomDataset(val_texts, val_labels, tokenizer, max_length)\n",
        "test_dataset = CustomDataset(test_texts, test_labels, tokenizer, max_length)"
      ],
      "metadata": {
        "id": "OXDdz2QABN5M"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eckMQQAxBPPr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Vectorización"
      ],
      "metadata": {
        "id": "5vJkVg9X7cOx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3TG0_Tea7cVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Entrenamiento y evaluación de modelos\n"
      ],
      "metadata": {
        "id": "Y1EtZHFx7ij9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCL0Gyb192T3"
      },
      "source": [
        "Para realizar el entrenamiento, cargamos el modelo en el entorno de ejecución.\n",
        "Utilizaremos AutoModelForSequenceClassification(), donde carga modelos que van a ser ajustados para clasificar secuencias de textos.\n",
        "\n",
        "Especificaremos el número de etiquetas que tenemos en nuestro problema de clasificación e introducimos unos diccionarios para gestionar y comprender mejor la salida del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNGEqXOcBkKp",
        "outputId": "35d0ce83-edf8-4728-a500-5cc7c5ffa979"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-2019-90m and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "id2label = {0: \"NO_CYBERBULLYING\", 1: \"CYBERBULLYING\"}\n",
        "label2id = {\"NO_CYBERBULLYING\": 0, \"CYBERBULLYING\": 1}\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name,  num_labels=2, id2label=id2label, label2id=label2id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vskFUp-jI_bF"
      },
      "source": [
        "Consecutivamente, definimos algunos parámetros para llevar a cabo el entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "IIjMnsxhJG5j"
      },
      "outputs": [],
      "source": [
        "import accelerate\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"modelo_test\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=4,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ffONxHxJJJI"
      },
      "source": [
        "Generamos una función de cálculo de métricas de evaluación durante el entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "3YARoS0zJPa1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "f1_score = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    accuracy_value = accuracy.compute(predictions=predictions, references=labels)\n",
        "    f1_score_value = f1_score.compute(predictions=predictions, references=labels)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy_value,\n",
        "        \"f1_score\": f1_score_value,\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSErXpbXJSJS"
      },
      "source": [
        "Creamos el objeto Trainer(), que nos permitirá llevar a cabo el ajuste del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Og8xAWoFJ36K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aa2e784-253c-4a60-9c0f-0e13e09f87c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "g4BXRWO7J5yO",
        "outputId": "0a1f31e0-1d42-4b75-f9bd-7cd9d2fdb7e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='14308' max='14308' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [14308/14308 55:13, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.278900</td>\n",
              "      <td>0.251259</td>\n",
              "      <td>{'accuracy': 0.9001956947162426}</td>\n",
              "      <td>{'f1': 0.9411861614497529}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.235700</td>\n",
              "      <td>0.300008</td>\n",
              "      <td>{'accuracy': 0.899077439194856}</td>\n",
              "      <td>{'f1': 0.9413294327970096}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.201500</td>\n",
              "      <td>0.453705</td>\n",
              "      <td>{'accuracy': 0.8969807100922561}</td>\n",
              "      <td>{'f1': 0.9396643471142039}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.164000</td>\n",
              "      <td>0.568260</td>\n",
              "      <td>{'accuracy': 0.8927872518870562}</td>\n",
              "      <td>{'f1': 0.9369398996957987}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"{'accuracy': 0.9001956947162426}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'f1': 0.9411861614497529}\" of type <class 'dict'> for key \"eval/f1_score\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'accuracy': 0.899077439194856}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'f1': 0.9413294327970096}\" of type <class 'dict'> for key \"eval/f1_score\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'accuracy': 0.8969807100922561}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'f1': 0.9396643471142039}\" of type <class 'dict'> for key \"eval/f1_score\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'accuracy': 0.8927872518870562}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'f1': 0.9369398996957987}\" of type <class 'dict'> for key \"eval/f1_score\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=14308, training_loss=0.21605671068660234, metrics={'train_runtime': 3313.6413, 'train_samples_per_second': 34.542, 'train_steps_per_second': 4.318, 'total_flos': 7528922849126400.0, 'train_loss': 0.21605671068660234, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLMCXfjtJ8rV"
      },
      "source": [
        "## Evaluación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4JUqUGLJ_Gs"
      },
      "source": [
        "Ya entrenado el modelo, llevaremos a cabo su evaluación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "qB9Aq5v3J-Re",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "489ebce4-7abc-47e3-be97-ce4289d59692"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1491' max='1491' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1491/1491 01:27]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"{'accuracy': 0.8936509267801728}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'f1': 0.9374012638230649}\" of type <class 'dict'> for key \"eval/f1_score\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.2630043625831604,\n",
              " 'eval_accuracy': {'accuracy': 0.8936509267801728},\n",
              " 'eval_f1_score': {'f1': 0.9374012638230649},\n",
              " 'eval_runtime': 88.009,\n",
              " 'eval_samples_per_second': 135.475,\n",
              " 'eval_steps_per_second': 16.941,\n",
              " 'epoch': 4.0}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "# Make predictions on the test data\n",
        "trainer.evaluate(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iRlRyWx0Qbhd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unrhEXjKKTNF"
      },
      "source": [
        "Haremos un classification report para ver los scores relativos a cada categoría. Para eso, predeciremos las etiquetas sobre el test set con el método .predict(). Y obtendremos la etiqueta de cada predicción."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Nw3FaSGmKyO3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "b09e59dc-0550-4ef3-ffe8-5080b1407610"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Make predictions on the test data\n",
        "predictions = trainer.predict(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "0BcSgXEpK0To",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a765387-8214-429f-f3d8-eed4f95db110"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.0583556,  2.5988815], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "predictions[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "Xsk6QdfIK15h"
      },
      "outputs": [],
      "source": [
        "# Access the predicted labels\n",
        "y_pred = predictions.predictions.argmax(axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8XtCzRSK3on"
      },
      "source": [
        "Cogemos las etiquetas verdaderas y calculamos el classification report:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "5FPbGICxK8RT"
      },
      "outputs": [],
      "source": [
        "y_true = [x[\"labels\"].item() for x in test_dataset]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "0hbbtHAXK-M1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90723f54-500e-43b0-cf7a-6ca7b956bf16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1161  825]\n",
            " [ 443 9494]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.58      0.65      1986\n",
            "           1       0.92      0.96      0.94      9937\n",
            "\n",
            "    accuracy                           0.89     11923\n",
            "   macro avg       0.82      0.77      0.79     11923\n",
            "weighted avg       0.89      0.89      0.89     11923\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(y_true,y_pred))\n",
        "print(classification_report(y_true,y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hd4Rh3d_LIJu"
      },
      "source": [
        "Podemos comparar los resultados con el clasificador obtenido mediante ingeniería de características."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGa6t0pFLTpQ"
      },
      "source": [
        "Podemos predecir cualquier frase o tweet de forma simple:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "IoLgYvJ8LHl2"
      },
      "outputs": [],
      "source": [
        "# Create a function to predict for a single document\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def predict_single_document(document, max_length=128):\n",
        "    # Tokenize the input document\n",
        "    inputs = tokenizer(document, return_tensors=\"pt\", max_length=max_length, truncation=True)\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}  # Move tensors to the same device as the model\n",
        "\n",
        "    # Make the prediction\n",
        "    with torch.no_grad():\n",
        "      model_output = trainer.model(**inputs)\n",
        "\n",
        "    # Access the predicted labels\n",
        "    predicted_label = torch.argmax(model_output.logits).item()\n",
        "\n",
        "    return predicted_label"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probamos con insertar tweets reales de cyberbullying y no cyberbullying, para saber si los predice correctamente."
      ],
      "metadata": {
        "id": "ff24p_Q5Q9f1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "lPAbvYW5LduB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd403819-41c2-45ab-d9c8-33db3465e07b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clase texto 1: 1\n",
            "Clase texto 2: 0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "input_text1 = 'Going to Africa. Hope I do not get AIDS. Just kidding. I am white'\n",
        "input_text2 = 'I feel so lucky with my job and my friends.'\n",
        "\n",
        "pred1 = predict_single_document(input_text1)\n",
        "pred2 = predict_single_document(input_text2)\n",
        "\n",
        "# label_mapping = {0:\"no cyberbullying\",1:\"cyberbullyng\"}\n",
        "\n",
        "print(\"Clase texto 1: {}\".format(pred1))\n",
        "print(\"Clase texto 2: {}\".format(pred2))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Comparación Ejercicio 1 y Ejercicio 2.**\n",
        "\n",
        "Como podemos observar, la diferencia del haber usado un *algoritmo de aprendizaje supervisado de clasificación*, en nuestro caso Random Forest y de un *modelo de lenguaje* que ha sido previamente preentrenado donde ha realizado el fine-tunning de clasificación de tweets sobre cyberbullying, creando una red neuronal simple, es notorio en los resultados.\n",
        "\n",
        "Obtenemos un accurracy  mayor a la hora de predecir tweets con el modelo de lenguaje (0.89) que con el algoritmo de clasificación (0.85).\n",
        "\n",
        "Finalmente, es importante añadir que en cuanto a elección del modelo, elegiríamos el modelo de lenguaje ya que además de obtener un mayor porcentaje de predicción, es un modelo capaz de capturar la información contextual del texto.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GI9I8I1KRlkO"
      }
    }
  ]
}